args:
    device: 'cuda:0'
    DEBUG: False
    transfer: False

    #results_dir: './clip_vit/'
    #results_dir: './new_pretrained_fullgrad_clip_comparison/'
    #results_dir: './again_again_new_test/'
    #results_dir: './long_pretrain_weighted_fixed/'
    #results_dir: './tune_long_pretrain_weighted_fixed/'
    #results_dir: './noise_long_pretrain_weighted_fixed/'
    
    pretrained_model_path: "./FACTFORMER_PRETRAINED_MODELS/"
    
    results_dir: './veryfinetune_PARALLEL_TEST/'
    #results_dir: './test_PARALLEL_TEST/'
    #
    dataset: 'all'
    pretraining_loss: 'clip'
    clip: True

    # Pick llm
    llm: 'all-mpnet-base-v2'
    #llm: 'all-MiniLM-L6-v2'

    normalize: False
    bcs: False
    coeff: False
    eq_coeff: False
    time: False
    qualitative: False
    sentence: False

    pushforward: 1
    t_bundle: 1

    train_style: 'next_step'
    #train_style: 'fixed_future'
    num_workers: 0
    batch_size: 64
    pretraining_batch_size: 128

    #initial_step: 1
    initial_step: 5
    #initial_step: 20
    #initial_step: 41
    #
    t_train: 200
    validate: 1
    #data_name: '2d_ns_1s_256_4eq.h5'
    #data_name: '2d_ns_30s_256_370eq.h5'
    data_name: '2d_electric_100_60.h5'
    #data_name: 'hba'
    base_path: '/home/cooperlorsung/'
    return_text: True
    reduced_resolution: 4
    reduced_resolution_t: 1
    reduced_batch: 1
    #split_style: 'equation' # 'initial_condition' or 'equation'
    split_style: 'initial_condition' # 'initial_condition' or 'equation'
    embedding: 'None'
    #embedding: 'clip'
    #embedding: 'llm'
    #embedding: 'oformerllm'
    llm: 'all-MiniLM-L6-v2'
    #llm: 'all-mpnet-base-v2'
    load_pretrained: True

    # CLIP
    embed_dim: 32
    downsample: 2
    detach: False

    # Optimizer
    learning_rate: 1.e-5
    weight_decay: 1.e-9
    scheduler_step: 20
    scheduler_gamma: 0.5

    epochs: 1000
    #epochs: 1

    #epochs: 10
    #epochs: 500
    num_seeds: 1

    pretraining_learning_rate: 1.e-3
    pretraining_weight_decay: 1.e-4
    #pretraining_epochs: 10
    #pretraining_epochs: 200
    pretraining_epochs: 2000

    # Sim samples
    img_size: 128
    #img_size: 64
    #img_size: 16
    num_t: 100
    #num_x: 64
    #num_y: 64
    num_x: 100
    num_y: 60

    sim_time: 21
    #sim_time: 80
    #sim_time: 120
    #sim_time: 999

    num_samples: 100
    #num_samples: 500
    #num_samples: 1000
    #num_samples: 2000
    pretraining_num_samples: 50
    #pretraining_num_samples: 100
    #pretraining_num_samples: 300

    samples_per_equation: 1
    #samples_per_equation: 5

    # FactFormer
    depth: 1
    dim: 64
    dim_head: 64
    heads: 4
    in_dim: 4
    out_dim: 4
    pos_in_dim: 2
    pos_out_dim: 2
    kernel_multiplier: 2
    latent_multiplier: 2.0
    max_latent_steps: 4

    dropout: 0.01

    # Tracking
    log_freq: 10
    progress_plot_freq: 50

